package com.zhh.handsome.线程和虚拟线程和go协程;

public class Go协程的优势底层原理 {




    /*go协程好神奇。线程是怎么完成携程的上下文切换的，上下文保存有是如何做到的，，这是什么新算法吗，为什么可以把原来需要用户态->内核态->用户态，然后全量上下文保存，优化成了全部在用户态切换，并且保存的东西也更轻量了呢，怎么做到让线程调度协程这么丝滑的，借助了操作系统切换时间片的逻辑吗
    你觉得 Go 协程的切换机制很神奇，核心想搞懂：Go 是怎么让 OS 线程完成协程上下文切换的？上下文保存的底层实现是什么？为什么能砍掉内核态切换、精简保存数据？是否借助了 OS 的时间片逻辑？
    首先明确核心结论：Go 协程的切换不是靠新算法，而是对经典 “用户级线程（ULT）” 模型的工程化极致优化（M-P-G 架构）—— 核心是把 “调度权从 OS 内核拿回用户态”，再配合 “极简上下文设计”，才实现了无内核态切换、轻量保存的丝滑效果；它没有借助 OS 的时间片逻辑，而是自己实现了用户态的调度规则。
    下面我会从 “底层架构基础→上下文定义→切换流程→优化核心→与 OS 时间片的关系” 一步步拆解，全程超详细、通俗，配比喻和底层实现细节。
    一、先补基础：Go 能在用户态切换的核心 ——M-P-G 架构
    要理解协程切换，必须先懂 Go 的 M-P-G 模型（这是用户态调度的根基），对比 Java 的 1:1 模型：
    模型	Java（1:1）	Go（M-P-G，多对多）
    调度权	完全交给 OS 内核	Go 运行时（用户态程序）掌控协程调度，OS 只掌控 OS 线程（M）
    核心角色	Java 线程 ↔ OS 线程（1:1 绑定）	协程（G）、逻辑处理器（P）、OS 线程（M）（多对多）
    关键差异	无中间层，直接依赖 OS 调度	P 是 “用户态调度器”，绑定 M 后，P 内部自己调度 G，不用通知 OS
    通俗比喻
    Java：你（JVM）雇工人（Java 线程），但工人的工作安排全由老板（OS）说了算 —— 工人干累了 / 卡住了，只能等老板重新安排；
    Go：你（Go 运行时）雇了 “包工头（P）”，包工头手下有 “工人（M，OS 线程）”，你把小工单（G）分给包工头，包工头自己安排工人干哪个工单，不用每次找老板（OS）请示。
    核心关键点：P 是用户态的 “调度器”，它持有一个 G 的就绪队列，P 绑定 M 后，直接在 M 上切换 G 的执行 —— 这个过程全程在用户态完成，完全绕开 OS 内核的调度干预。*/

















   /* 二、Go 协程的 “上下文” 到底是什么？（为什么能轻量）
    Java 线程的上下文是 “全量内核态 + 用户态数据”，而 Go 协程的上下文是 “用户态极简核心数据”，先明确两者的对比：
            1. Go 协程（G）的上下文定义（仅几十字节）
    Go 的每个 G 都对应一个g结构体（源码：runtime/runtime2.go），其中 “切换时需要保存 / 恢复的上下文” 只有一个字段：g.sched（调度上下文），里面只存CPU 执行 G 所需的最小核心寄存器，具体如下：
    字段	含义	作用	大小
    pc	程序计数器	记录 G 当前执行到哪条机器指令（比如执行到sum += i的哪一步）	8 字节（64 位）
    sp	栈指针	指向 G 的用户态栈的当前位置（G 的栈是用户态的，初始 2KB，可伸缩）	8 字节
    bp	基指针	辅助定位栈帧（方法调用的栈帧边界）	8 字节
    g	当前 G 的指针	让 CPU 知道当前执行的是哪个 G	8 字节
    tls	线程局部存储指针	少量线程私有数据（极简）	8 字节
    通用寄存器	AX/BX/CX 等（存储临时计算结果）	仅保存几个核心通用寄存器，而非全部	~16 字节
    总计：G 的上下文数据≈56 字节（64 位系统），对比 Java 线程的 “几十 KB”，差距是 1000 倍以上。
            2. 为什么只存这些就够？（底层逻辑）
    CPU 执行程序的本质是 “根据 PC 取指令，用寄存器计算，用 SP/BP 访问栈”—— 只要保存这几个核心寄存器，就能精准恢复 G 的执行状态：
    比如 G 执行到sum += i时被切换，保存pc（下一条指令地址）、sp（sum 变量在栈里的位置）、AX（i 的当前值）；恢复时，把这些值写回 CPU 寄存器，CPU 就能从断点继续执行，完全不用管其他数据。
    而 Java 线程需要保存 “内核栈、页表、TLB” 等，是因为 OS 要管控线程的所有资源（比如内存访问、权限），而 Go 的 G 运行在 P 绑定的 M 上，M 的内存权限、页表已经由 OS 初始化完成，Go 运行时只需要管 “G 的执行位置”，不用管底层资源。*/




    /*

    通俗比喻
    Java 线程的上下文：保存一个厨师的 “全套厨具 + 食材 + 烹饪步骤 + 厨房门禁卡 + 水电表”（OS 要管所有资源）；
    Go 协程的上下文：只保存厨师的 “当前炒到哪一步（pc）+ 锅铲放哪（sp）+ 手里的食材（寄存器）”（包工头只管炒菜，不管厨房门禁、水电）。
    三、OS 线程（M）上切换 Go 协程（G）的完整流程（用户态切换的核心）
    Go 协程的切换全程由 Go 运行时（用户态）的runtime.switchto函数（汇编实现）完成，没有任何内核态切换。下面以 “G1 阻塞→切换到 G2” 为例，拆解每一步底层逻辑：
    前置条件
    P（逻辑处理器）已绑定 M（OS 线程），P 的就绪队列里有 G1、G2；
    M 正在执行 G1，G1 执行到time.Sleep(1s)（触发阻塞）。
    切换流程（全程用户态）



    关键步骤的底层实现细节（通俗版）
    步骤 1：保存 G1 的上下文（汇编核心逻辑）
    Go 的switchto函数是用汇编写的（源码：runtime/asm_amd64.s），核心代码逻辑（简化版）：
    asm
    // 保存当前G（G1）的上下文到g.sched
    MOVQ    PC, (g_sched_pc)(SI)  // 将当前PC值写入g1.sched.pc
    MOVQ    SP, (g_sched_sp)(SI)  // 将当前SP值写入g1.sched.sp
    MOVQ    BP, (g_sched_bp)(SI)  // 将当前BP值写入g1.sched.bp
    // 保存通用寄存器（如AX/BX）
    MOVQ    AX, (g_sched_ax)(SI)
    MOVQ    BX, (g_sched_bx)(SI)
    // 标记G1状态为阻塞
    MOVQ    $Gwaiting, (g_status)(SI)
    这些指令全程在用户态执行：CPU 直接把寄存器值写入 G1 的g.sched结构体（用户态内存），不用通知 OS；
    耗时：汇编指令执行速度是纳秒级，这一步总耗时≈10 纳秒。
    步骤 2：P 选择下一个 G（用户态调度）
    P 的就绪队列是 Go 运行时维护的链表（用户态数据结构），选 G2 的逻辑是：
    先从 P 的本地就绪队列取（最快）；
    本地队列空了，就从其他 P 偷（work stealing 机制）；
    都空了，就从全局队列取。
    这个过程是纯 Go 代码（用户态），没有任何系统调用（系统调用才会切内核态）。
    步骤 3：恢复 G2 的上下文（汇编核心逻辑）
    asm
// 从g2.sched恢复上下文到CPU寄存器
    MOVQ    (g_sched_pc)(DI), PC  // 将g2.sched.pc写回CPU的PC寄存器
    MOVQ    (g_sched_sp)(DI), SP  // 恢复栈指针
    MOVQ    (g_sched_bp)(DI), BP  // 恢复基指针
// 恢复通用寄存器
    MOVQ    (g_sched_ax)(DI), AX
    MOVQ    (g_sched_bx)(DI), BX
    // 标记G2状态为运行态
    MOVQ    $Grunning, (g_status)(DI)
    执行完这些汇编指令，CPU 的 PC 寄存器指向 G2 上次暂停的指令地址，SP 指向 G2 的栈，直接继续执行 G2—— 全程没有内核态切换，没有 OS 干预。
    对比 Java 线程切换的核心差异
    步骤	Java 线程切换	Go 协程切换
    触发者	OS 内核（中断 / 时间片耗尽）	Go 运行时（用户态，G 阻塞 / 主动让出）
    模式切换	用户态→内核态→用户态	全程用户态
    上下文保存 / 恢复	OS 内核操作，保存几十 KB	Go 运行时汇编操作，保存几十字节
    耗时	1-10 微秒	10-100 纳秒
    四、为什么 Go 能做到 “用户态切换 + 轻量保存”？（核心优化点）
    不是靠 “新算法”，而是靠 3 个底层设计的组合拳，从根上规避了 Java 的问题：
    优化 1：把调度权从 OS 内核拿回 “用户态”（核心中的核心）
    Java 的问题：线程调度权完全在 OS，切换必须走内核态（因为 OS 要管控线程的所有资源）；
    Go 的解法：
    用 P 作为 “用户态调度器”，P 绑定 M 后，M 的资源（内存、权限、页表）已经由 OS 初始化完成；
    Go 运行时只管控 G 的 “执行逻辑”（什么时候切换、执行哪个 G），不管 M 的底层资源；
    切换 G 时，只需要改 CPU 的寄存器（用户态操作），不用动 M 的资源，因此不用通知 OS，也就不用切内核态。
    优化 2：极简上下文设计（只存 “执行断点”，不存 “资源信息”）
    Java 的问题：OS 要管控线程的所有资源，所以上下文必须包含 “内核栈、页表、TLB” 等资源信息，数据量大；
    Go 的解法：
    G 的上下文只存 “CPU 执行的断点信息”（PC/SP/ 寄存器），这些是 “执行逻辑”，不是 “资源信息”；
    资源信息（如内存页表）由 M 管控，M 的资源由 OS 初始化后就不变，切换 G 时不用动这些资源，因此不用保存。
    优化 3：主动触发切换（避免被动等 OS 中断）
    Go 协程的切换是 “主动触发”，而非像 Java 那样 “被动等 OS 时间片耗尽”：
    触发切换的时机（全在用户态检测）：
    G 执行 IO 操作（如net.Read）、time.Sleep、channel阻塞；
    G 主动调用runtime.Gosched()让出 CPU；
    G 执行时间超过 Go 的 “用户态时间片”（默认 10ms），由 Go 运行时的信号量触发切换；
    主动切换的好处：Go 运行时可以 “优雅保存上下文”，不用像 OS 那样靠中断强制切换（中断会额外增加开销）。
    五、Go 协程的调度是否借助了 OS 的时间片逻辑？
    结论：完全没有——Go 有自己的 “用户态时间片”，OS 的时间片只作用于 M（OS 线程），不直接作用于 G（协程）。
            1. OS 的时间片：只管 M，不管 G
    OS 给每个 M（OS 线程）分配时间片（比如 100ms），M 在这个时间片内可以被 CPU 执行；但 M 上跑的是 P，P 可以在 M 的时间片内切换成百上千个 G——OS 完全不知道 G 的存在，只知道 “M 在执行 Go 程序”。
            2. Go 的用户态时间片：管控 G 的执行时长
    Go 运行时自己给每个 G 设置了 “用户态时间片”（默认 10ms），目的是防止某个 G 长时间占用 M：
    实现方式：Go 运行时启动一个 “调度器线程”，每隔 10ms 向所有运行中的 M 发送一个信号；
    信号处理：M 收到信号后，在用户态触发 G 的切换（保存当前 G，选下一个 G），全程不进入内核态；
    对比 OS 时间片：OS 的时间片是 “硬件中断触发、内核态处理”，Go 的时间片是 “用户态信号、用户态处理”。
    通俗比喻
    OS 给 M 的时间片：老板给工人（M）分配 1 小时的工作时间；
    Go 给 G 的时间片：包工头（P）规定工人在这 1 小时内，每个工单（G）最多干 10 分钟，到点就换工单 —— 老板完全不知道工单的存在，只知道工人在干活。
    六、为什么 Go 的切换这么 “丝滑”？（总结）
    丝滑的核心是 “无内核态切换 + 极简上下文 + 主动调度”，量化对比：
    操作	Java 线程切换	Go 协程切换	差距
    模式切换	用户态↔内核态↔用户态	全程用户态	减少 1-10 微秒
    上下文数据量	几十 KB	几十字节	减少 1000 倍
    触发方式	被动中断	主动触发	更优雅，无中断开销
    总耗时	1-10 微秒	10-100 纳秒	快 10-100 倍
    总结（核心要点回顾）
    用户态切换的根基：M-P-G 架构中，P 作为用户态调度器，掌控 G 的调度权，绕开 OS 内核，这是能在用户态切换的核心；
    轻量上下文的关键：G 的上下文只存 “CPU 执行断点（PC/SP/ 寄存器）”，仅几十字节，不用保存内核态资源信息；
    切换的底层实现：由 Go 运行时的汇编函数switchto完成上下文保存 / 恢复，全程用户态，无系统调用；
    与 OS 时间片的关系：OS 时间片只管 M，Go 自己实现用户态时间片管控 G，完全不借助 OS 的调度逻辑；
    核心优化逻辑：不是新算法，而是 “把调度权从内核拿回用户态”+“极简上下文设计” 的工程化优化。
    简单来说，Go 协程的切换丝滑，本质是 “把 OS 内核的‘重活’（全量上下文、内核态切换）砍掉，只保留用户态的‘轻活’（极简上下文、用户态切换）”—— 这也是为什么 Go 能轻松支撑百万协程，而 Java 线程只能到几千的根本原因。

    */





















  /*  所以说即便go一百个协程底层可能也就三四个线程，java一百个线程，即便这时候go可能也需要进行线程的全量上下文切换，但是由于数量远远小于java的一百个线程，所以效率依然天差地别
    你这个判断完全精准，而且说到了 Go 和 Java 并发效率差异的核心 ——不是 “有没有全量线程切换”，而是 “全量切换的次数 / 规模” 天差地别：Go 即便有线程的全量上下文切换，也因为底层线程数量极少（3-4 个），总开销远低于 Java 100 个线程的全量切换，再叠加 Go 协程的用户态轻量切换，最终效率差距呈数量级拉开。
    下面我会把这个逻辑拆透，用 “场景对比 + 量化计算” 让你直观看到 “天差地别” 的具体来源：
    一、先明确核心前提：Go 的 “线程全量切换” 和 Java 的 “线程全量切换”，场景完全不同
    首先要纠正一个小细节：Go 底层的 3-4 个 OS 线程（M），只有当 OS 内核调度这些 M 本身时，才会触发 “全量上下文切换”；而 Go 协程（G）之间的切换是用户态轻量切换，和 OS 的全量切换无关。
    我们用 “100 个并发任务” 的场景，对比 Go 和 Java 的切换开销：
    场景：处理 100 个并发计算任务（无 IO 阻塞）
    维度	Go（100 协程）	Java（100 线程）
    底层 OS 线程数量	3-4 个（M）（等于 CPU 核心数，默认 GOMAXPROCS）	100 个（1:1 绑定，每个 Java 线程对应 1 个 OS 线程）
    核心切换类型	99% 是 G 的用户态轻量切换（10-100 纳秒 / 次）
            1% 是 M 的 OS 全量切换（1-10 微秒 / 次）	100% 是 OS 全量线程切换（1-10 微秒 / 次）
    全量切换的触发场景	只有 OS 调度 3-4 个 M 时才会触发（比如 M 的时间片耗尽），次数极少	OS 需要调度 100 个线程，每次线程切换都是全量切换，次数极多
    二、量化计算：100 个并发任务的 “总切换开销” 对比
    我们用具体的数值计算（取中间值，便于对比），直观看效率差距：
    基础参数（行业通用实测值）
    Go 协程（G）用户态切换耗时：50 纳秒 / 次；
    OS 线程全量切换耗时：5 微秒 / 次（=5000 纳秒 / 次）；
    假设每个任务执行过程中需要切换 10 次（模拟并发调度）。
            1. Go 的总切换开销
100 个协程在 3-4 个 M 上切换，核心是G 的用户态切换：
    总切换次数≈100 个协程 × 10 次切换 = 1000 次；
    总开销≈1000 次 × 50 纳秒 / 次 = 50000 纳秒（50 微秒）；
    额外的 M 全量切换：3-4 个 M 被 OS 调度，假设切换 10 次（极端情况）：
    额外开销≈10 次 × 5000 纳秒 / 次 = 50000 纳秒（50 微秒）；
    Go 总切换开销≈50 + 50 = 100 微秒。
            2. Java 的总切换开销
100 个线程的切换全是 OS 全量切换：
    总切换次数≈100 个线程 × 10 次切换 = 1000 次；
    总开销≈1000 次 × 5000 纳秒 / 次 = 5000000 纳秒（5000 微秒 = 5 毫秒）；
    无其他额外开销（因为没有用户态切换）。
            3. 开销对比
    Java 的总切换开销 ≈ 50 倍 × Go 的总开销（5 毫秒 vs 0.1 毫秒）；如果任务更复杂、切换次数更多（比如每个任务切换 100 次），差距会扩大到500 倍。
    三、更关键的：Go 的 “线程全量切换” 几乎可以忽略
    你提到 “Go 可能也需要进行线程的全量上下文切换”，但实际场景中，这个切换的影响微乎其微，原因有二：
            1. M 的数量等于 CPU 核心数，OS 调度压力极小
    OS 的线程调度开销，和 “线程数量 / 核心数的比值” 正相关：
    Go：3-4 个 M / 4 核 CPU = 1:1，OS 几乎不需要频繁调度（每个 M 绑定一个核心，时间片用完才切换）；
    Java：100 个线程 / 4 核 CPU = 25:1，OS 需要疯狂调度（25 个线程抢 1 个核心），全量切换次数呈指数级增加。
            2. Go 的 M 切换是 “被动且低频”，Java 是 “主动且高频”
    Go 的 M 只有两种情况会触发 OS 全量切换：
            ① M 的 OS 时间片耗尽（比如 100ms 一次）；
            ② M 绑定的 P 被抢占（极端场景）；
    这两种情况的触发频率以 “毫秒级” 计，远低于 G 的用户态切换（微秒级）。
    Java 的线程切换是 “高频且必然”：100 个线程抢 4 个核心，OS 每秒要做几百次全量切换，这些切换的总开销会直接吃掉大量 CPU 资源。
    四、通俗比喻：工厂流水线对比
    把 CPU 核心比作 “4 个生产工位”，帮你理解：
    Java 场景：雇了 100 个工人（线程），每个工人占一个 “工位资格”，车间主任（OS）要不停安排这 100 个工人轮流用 4 个工位 —— 每次换工人，都要让工人把 “全套工具 + 食材 + 记录”（全量上下文）打包 / 恢复，100 个工人换来换去，光打包 / 恢复的时间就占了 80% 的生产时间；
    Go 场景：只雇了 4 个工人（M），每个工人管 25 个 “工单”（G），车间主任只需要偶尔给这 4 个工人排班（低频全量切换）；工人自己在工位上快速换工单（用户态切换），换工单只需要 “记一下当前做到哪一步”（轻量上下文），打包 / 恢复的时间只占 1% 的生产时间。
    总结（核心要点回顾）
    核心差异是 “全量切换的规模”：Go 底层线程数（3-4 个）远少于 Java 的线程数（100 个），即便有全量线程切换，总开销也只有 Java 的 1/50 甚至 1/100；
    切换类型的叠加优势：Go 的协程切换是用户态轻量切换（50 纳秒），而 Java 全是 OS 重量切换（5000 纳秒），进一步放大效率差距；
    调度频率的差距：Java 的线程调度是 “25:1 抢核心”，切换次数指数级增加；Go 的线程调度是 “1:1 绑定核心”，切换次数极少。
    简单来说，Go 的高效不是 “避免了线程的全量切换”，而是 “把全量切换的次数降到了极致”，再用轻量的用户态协程切换承接大部分并发需求 —— 这就是为什么哪怕是相同的并发量，Go 的效率也和 Java 天差地别。*/



}
